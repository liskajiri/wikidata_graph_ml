{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liskaj/.conda/envs/pyg_graphs/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch_wikidata import Wikidata5m\n",
    "\n",
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.RandomLinkSplit(num_val=0, num_test=0.01, is_undirected=True, add_negative_train_samples=False),\n",
    "])\n",
    "\n",
    "dataset = Wikidata5m(\"datasets/\", transform=transform)\n",
    "\n",
    "train_data, _, test_data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[4796490, 1], edge_index=[2, 5847710], edge_label=[2923855], edge_label_index=[2, 2923855]),\n",
       " Data(x=[4796490, 1], edge_index=[2, 5847710], edge_label=[59066], edge_label_index=[2, 59066]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load embeddings and transform them to torch matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load(\"sentence_features.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.ones((train_data.x.shape[0], features.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:features.shape[0], :] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_features = torch.from_numpy(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_features = torch_features.to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_features.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.x = torch_features\n",
    "test_data.x = torch_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "batch_size = 512\n",
    "n_neighbors = [10] * 2\n",
    "\n",
    "def make_link_loaders(train_data, test_data) -> [LinkNeighborLoader, LinkNeighborLoader]:\n",
    "    train_loader = LinkNeighborLoader(\n",
    "        train_data,\n",
    "        num_neighbors=n_neighbors,\n",
    "        batch_size=batch_size,\n",
    "        edge_label_index=train_data.edge_label_index,\n",
    "        neg_sampling_ratio=1.0,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    test_loader = LinkNeighborLoader(\n",
    "        test_data,\n",
    "        num_neighbors=n_neighbors,\n",
    "        batch_size=batch_size,\n",
    "        edge_label_index=test_data.edge_label_index,\n",
    "        neg_sampling_ratio=1.0,\n",
    "        shuffle=True\n",
    "    )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = make_link_loaders(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNNet(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCNNet(train_data.num_features, 256, 256).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(loader: LinkNeighborLoader):\n",
    "    model.train()\n",
    "    loss = 0\n",
    "    for batch in tqdm(loader):\n",
    "        optimizer.zero_grad()\n",
    "        batch.to(device)\n",
    "\n",
    "        z = model.encode(batch.x, batch.edge_index)\n",
    "        out = model.decode(z, batch.edge_label_index).view(-1)\n",
    "        loss = criterion(out, batch.edge_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    aucs = 0\n",
    "    for batch in tqdm(loader):\n",
    "        batch.to(device)\n",
    "        \n",
    "        z = model.encode(batch.x, batch.edge_index)\n",
    "        out = model.decode(z, batch.edge_label_index).view(-1).sigmoid()\n",
    "        aucs += roc_auc_score(batch.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "    return aucs / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accs = []\n",
    "losses = []\n",
    "\n",
    "avg_test_auc = 0\n",
    "total_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5711/5711 [07:57<00:00, 11.97it/s]\n",
      "100%|██████████| 116/116 [00:06<00:00, 17.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.4291, Test AUC: 0.6488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5711/5711 [08:02<00:00, 11.83it/s]\n",
      "100%|██████████| 116/116 [00:06<00:00, 17.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 0.4418, Test AUC: 0.6484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5711/5711 [08:04<00:00, 11.78it/s]\n",
      "100%|██████████| 116/116 [00:06<00:00, 17.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Loss: 0.4358, Test AUC: 0.6486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5711/5711 [08:07<00:00, 11.72it/s]\n",
      "100%|██████████| 116/116 [00:06<00:00, 17.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Loss: 0.4387, Test AUC: 0.6491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5711/5711 [08:07<00:00, 11.71it/s]\n",
      "100%|██████████| 116/116 [00:06<00:00, 17.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Loss: 0.4559, Test AUC: 0.6487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 6):\n",
    "    loss = train(train_loader)\n",
    "    auc = test(test_loader)\n",
    "    avg_test_auc += auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Test AUC: {avg_test_auc/total_epochs:.4f}')\n",
    "    test_accs.append(auc)\n",
    "    losses.append(loss)\n",
    "    total_epochs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(0.42912337, dtype=float32),\n",
       " array(0.44178107, dtype=float32),\n",
       " array(0.43575042, dtype=float32),\n",
       " array(0.43867433, dtype=float32),\n",
       " array(0.45592526, dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [loss for loss in losses]\n",
    "test_accs = [acc for acc in test_accs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nImage export using the \"kaleido\" engine requires the kaleido package,\nwhich can be installed using pip:\n    $ pip install -U kaleido\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m fig \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mline(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(losses)), y\u001b[38;5;241m=\u001b[39mlosses, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss during training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m fig\u001b[38;5;241m.\u001b[39mupdate_layout(xaxis_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, yaxis_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimages/loss_fig_embeddings.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/.conda/envs/pyg_graphs/lib/python3.10/site-packages/plotly/basedatatypes.py:3821\u001b[0m, in \u001b[0;36mBaseFigure.write_image\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3761\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;124;03mConvert a figure to a static image and write it to a file or writeable\u001b[39;00m\n\u001b[1;32m   3763\u001b[0m \u001b[38;5;124;03mobject\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3817\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[1;32m   3818\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3819\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[0;32m-> 3821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pyg_graphs/lib/python3.10/site-packages/plotly/io/_kaleido.py:267\u001b[0m, in \u001b[0;36mwrite_image\u001b[0;34m(fig, file, format, scale, width, height, validate, engine)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    252\u001b[0m                 \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03mCannot infer image type from output path '{file}'.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m                 )\n\u001b[1;32m    262\u001b[0m             )\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;66;03m# Request image\u001b[39;00m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;66;03m# -------------\u001b[39;00m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;66;03m# Do this first so we don't create a file if image conversion fails\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m     img_data \u001b[38;5;241m=\u001b[39m \u001b[43mto_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# Open file\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# ---------\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;66;03m# We previously failed to make sense of `file` as a pathlib object.\u001b[39;00m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;66;03m# Attempt to write to `file` as an open file descriptor.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pyg_graphs/lib/python3.10/site-packages/plotly/io/_kaleido.py:133\u001b[0m, in \u001b[0;36mto_image\u001b[0;34m(fig, format, width, height, scale, validate, engine)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# Raise informative error message if Kaleido is not installed\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scope \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    134\u001b[0m             \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03mImage export using the \"kaleido\" engine requires the kaleido package,\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03mwhich can be installed using pip:\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    $ pip install -U kaleido\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    139\u001b[0m         )\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# Validate figure\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# ---------------\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     fig_dict \u001b[38;5;241m=\u001b[39m validate_coerce_fig_to_dict(fig, validate)\n",
      "\u001b[0;31mValueError\u001b[0m: \nImage export using the \"kaleido\" engine requires the kaleido package,\nwhich can be installed using pip:\n    $ pip install -U kaleido\n"
     ]
    }
   ],
   "source": [
    "fig = px.line(x=range(len(losses)), y=losses, title=\"Loss during training\")\n",
    "fig.update_layout(xaxis_title=\"Epochs\", yaxis_title=\"Loss\")\n",
    "fig.write_image(\"images/loss_fig_embeddings.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=range(len(test_accs)), y=test_accs, title=\"Test ROC AUC score\")\n",
    "fig.update_layout(xaxis_title=\"Epochs\", yaxis_title=\"ROC AUC score\")\n",
    "fig.write_image(\"images/test_fig_embeddings.png\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg_kernel",
   "language": "python",
   "name": "pyg_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "c38629fd2b216446fae8efc32f1aa275963cb5ebed014889599f2e40172abad5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
