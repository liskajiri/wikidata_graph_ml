{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch_wikidata import Wikidata5m\n",
    "\n",
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started download\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.dropbox.com/s/6sbhm0rwo4l73jq/wikidata5m_transductive.tar.gz?dl=1\n",
      "Downloading https://www.dropbox.com/s/7jp4ib8zo3i6m10/wikidata5m_text.txt.gz?dl=1\n",
      "Downloading https://www.dropbox.com/s/lnbhc8yuhit4wm5/wikidata5m_alias.tar.gz?dl=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacking\n",
      "Finished download\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.RandomLinkSplit(num_val=0, num_test=0.001, is_undirected=True, add_negative_train_samples=False),\n",
    "])\n",
    "\n",
    "dataset = Wikidata5m(\"datasets/\", transform=transform)\n",
    "\n",
    "train_data, _, test_data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[4796490, 1], edge_index=[2, 5900870], edge_label=[2950435], edge_label_index=[2, 2950435]),\n",
       " Data(x=[4796490, 1], edge_index=[2, 5900870], edge_label=[5906], edge_label_index=[2, 5906]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "batch_size = 512\n",
    "n_neighbors = [10] * 2\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    train_data,\n",
    "    num_neighbors=n_neighbors,\n",
    "    batch_size=batch_size,\n",
    "    edge_label_index=train_data.edge_label_index,\n",
    "    neg_sampling_ratio=1.0\n",
    ")\n",
    "\n",
    "test_loader = LinkNeighborLoader(\n",
    "    test_data,\n",
    "    num_neighbors=n_neighbors,\n",
    "    batch_size=batch_size * 2,\n",
    "    edge_label_index=test_data.edge_label_index,\n",
    "    neg_sampling_ratio=1.0\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "model = Net(train_data.num_features, 512, 512).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[26605, 1], edge_index=[2, 37633], edge_label=[1024], edge_label_index=[2, 1024])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(loader: LinkNeighborLoader):\n",
    "    model.train()\n",
    "    n_iters = 10 #int(train_data.edge_index.size(-1) / batch_size)\n",
    "    for i in tqdm(range(n_iters)):\n",
    "        optimizer.zero_grad()\n",
    "        batch = next(iter(loader))\n",
    "\n",
    "        z = model.encode(batch.x, batch.edge_index)\n",
    "        out = model.decode(z, batch.edge_label_index).view(-1)\n",
    "        loss = criterion(out, batch.edge_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(dataloader):\n",
    "    model.eval()\n",
    "    aucs = 0\n",
    "    n_iters = 10 #int(train_data.edge_index.size(-1) / batch_size)\n",
    "    for i in tqdm(range(n_iters)):\n",
    "        batch = next(iter(dataloader))\n",
    "        z = model.encode(batch.x, batch.edge_index)\n",
    "        out = model.decode(z, batch.edge_label_index).view(-1).sigmoid()\n",
    "        aucs += roc_auc_score(batch.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "    return aucs / n_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.13it/s]\n",
      "100%|██████████| 10/10 [00:07<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.5778, Test: 0.7619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 0.5552, Test: 0.7607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "avg_test_acc = 0\n",
    "\n",
    "for epoch in range(1, 3):\n",
    "    loss = train(train_loader)\n",
    "    acc = test(test_loader)\n",
    "    avg_test_acc += acc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Test: {avg_test_acc/epoch:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_graphs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c38629fd2b216446fae8efc32f1aa275963cb5ebed014889599f2e40172abad5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
